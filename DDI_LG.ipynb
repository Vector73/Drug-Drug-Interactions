{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-dev-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04573d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-core in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-google-genai in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: tavily in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (2.32.5)\n",
      "Collecting neo4j\n",
      "  Downloading neo4j-6.0.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph) (2.12.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-core) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-google-genai) (0.9.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.42.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (6.33.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from tavily) (3.13.2)\n",
      "Collecting pytz (from neo4j)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from aiohttp->tavily) (1.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/kartik/.venvs/ddi-env/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Downloading neo4j-6.0.2-py3-none-any.whl (325 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, neo4j\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [neo4j]32m1/2\u001b[0m [neo4j]\n",
      "\u001b[1A\u001b[2KSuccessfully installed neo4j-6.0.2 pytz-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph langchain-core langchain-google-genai tavily requests neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e1a35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from typing import TypedDict, List, Dict, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Config\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"\")\n",
    "\n",
    "# State\n",
    "class DrugState(TypedDict):\n",
    "    drug_name: str\n",
    "    normalized_id: Optional[str]\n",
    "    source: Optional[str]\n",
    "\n",
    "# RxNorm API (FREE - replaces DrugBank)\n",
    "def search_rxnorm(drug_name: str) -> Optional[str]:\n",
    "    \"\"\"Search RxNorm API for drug identifier\"\"\"\n",
    "    try:\n",
    "        # Step 1: Get approximate term match\n",
    "        response = requests.get(\n",
    "            \"https://rxnav.nlm.nih.gov/REST/approximateTerm.json\",\n",
    "            params={\"term\": drug_name, \"maxEntries\": 5},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            candidates = data.get(\"approximateGroup\", {}).get(\"candidate\", [])\n",
    "            \n",
    "            if not candidates:\n",
    "                return None\n",
    "            \n",
    "            # Get first candidate's RxCUI\n",
    "            if isinstance(candidates, list):\n",
    "                rxcui = candidates[0].get(\"rxcui\")\n",
    "            else:\n",
    "                rxcui = candidates.get(\"rxcui\")\n",
    "            \n",
    "            if rxcui:\n",
    "                # Step 2: Get DrugBank ID from RxNorm properties\n",
    "                prop_response = requests.get(\n",
    "                    f\"https://rxnav.nlm.nih.gov/REST/rxcui/{rxcui}/allProperties.json\",\n",
    "                    params={\"prop\": \"all\"},\n",
    "                    timeout=10\n",
    "                )\n",
    "                \n",
    "                if prop_response.status_code == 200:\n",
    "                    prop_data = prop_response.json()\n",
    "                    properties = prop_data.get(\"propConceptGroup\", {}).get(\"propConcept\", [])\n",
    "                    \n",
    "                    # Look for DrugBank ID in properties\n",
    "                    for prop in properties:\n",
    "                        if prop.get(\"propName\") == \"DRUGBANK\":\n",
    "                            drugbank_id = prop.get(\"propValue\")\n",
    "                            if drugbank_id and drugbank_id.startswith(\"DB\"):\n",
    "                                return f\"Compound::{drugbank_id}\"\n",
    "                \n",
    "                # If no DrugBank ID, try to map via ChEMBL using the drug name\n",
    "                # Or return RxCUI format for now\n",
    "                return f\"Compound::RXCUI{rxcui}\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"RxNorm error: {e}\")\n",
    "    return None\n",
    "\n",
    "# ChEMBL API (FREE)\n",
    "def search_chembl(drug_name: str) -> Optional[str]:\n",
    "    \"\"\"Search ChEMBL API for drug identifier\"\"\"\n",
    "    try:\n",
    "        # Try molecule search\n",
    "        response = requests.get(\n",
    "            \"https://www.ebi.ac.uk/chembl/api/data/molecule/search.json\",\n",
    "            params={\"q\": drug_name, \"limit\": 5},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            molecules = data.get(\"molecules\", [])\n",
    "            if molecules:\n",
    "                chembl_id = molecules[0].get(\"molecule_chembl_id\")\n",
    "                if chembl_id and chembl_id.startswith(\"CHEMBL\"):\n",
    "                    return f\"Compound::{chembl_id}\"\n",
    "        \n",
    "        # Try drug-specific endpoint\n",
    "        response = requests.get(\n",
    "            \"https://www.ebi.ac.uk/chembl/api/data/drug.json\",\n",
    "            params={\"pref_name__icontains\": drug_name, \"limit\": 5},\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            drugs = data.get(\"drugs\", [])\n",
    "            if drugs:\n",
    "                chembl_id = drugs[0].get(\"molecule_chembl_id\")\n",
    "                if chembl_id and chembl_id.startswith(\"CHEMBL\"):\n",
    "                    return f\"Compound::{chembl_id}\"\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"ChEMBL error: {e}\")\n",
    "    return None\n",
    "\n",
    "# Tavily + LLM (Fallback)\n",
    "def search_tavily(drug_name: str) -> Optional[str]:\n",
    "    \"\"\"Use Tavily search + LLM to extract drug identifiers\"\"\"\n",
    "    if not TAVILY_API_KEY or not GEMINI_API_KEY:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash-exp\", \n",
    "            temperature=0, \n",
    "            api_key=GEMINI_API_KEY\n",
    "        )\n",
    "        \n",
    "        # Search for drug info\n",
    "        response = tavily.search(\n",
    "            f\"{drug_name} DrugBank ID CHEMBL ID drug database\",\n",
    "            search_depth=\"advanced\",\n",
    "            max_results=5\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for r in response.get(\"results\", []):\n",
    "            results.append(f\"Title: {r['title']}\\nContent: {r['content']}\\nURL: {r['url']}\\n\")\n",
    "        \n",
    "        if not results:\n",
    "            return None\n",
    "        \n",
    "        context = \"\\n---\\n\".join(results)\n",
    "        \n",
    "        prompt = f\"\"\"Extract the official drug database ID for: \"{drug_name}\"\n",
    "\n",
    "SEARCH RESULTS:\n",
    "{context}\n",
    "\n",
    "RULES:\n",
    "- DrugBank IDs: \"DB\" + exactly 5 digits (e.g., DB00945)\n",
    "- CHEMBL IDs: \"CHEMBL\" + digits (e.g., CHEMBL25)\n",
    "- Prefer DrugBank over CHEMBL\n",
    "- Output format: \"Compound::DBxxxxx\" or \"Compound::CHEMBLxxxx\"\n",
    "- If not found: \"NOT_FOUND\"\n",
    "\n",
    "OUTPUT (one line only):\"\"\"\n",
    "        \n",
    "        result = llm.invoke([\n",
    "            SystemMessage(content=\"You extract drug database identifiers.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        \n",
    "        extracted = result.content.strip()\n",
    "        \n",
    "        if re.match(r\"Compound::(DB\\d{5}|CHEMBL\\d+)\", extracted):\n",
    "            return extracted\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Tavily error: {e}\")\n",
    "    return None\n",
    "\n",
    "# LangGraph Nodes\n",
    "def try_rxnorm(state: DrugState) -> DrugState:\n",
    "    \"\"\"Try RxNorm API first\"\"\"\n",
    "    print(f\"  â†’ Trying RxNorm...\")\n",
    "    result = search_rxnorm(state[\"drug_name\"])\n",
    "    if result:\n",
    "        state[\"normalized_id\"] = result\n",
    "        state[\"source\"] = \"RxNorm\"\n",
    "        print(f\"    âœ“ Found: {result}\")\n",
    "    else:\n",
    "        print(f\"    âœ— Not found\")\n",
    "    return state\n",
    "\n",
    "def try_chembl(state: DrugState) -> DrugState:\n",
    "    \"\"\"Try ChEMBL API\"\"\"\n",
    "    print(f\"  â†’ Trying ChEMBL...\")\n",
    "    result = search_chembl(state[\"drug_name\"])\n",
    "    if result:\n",
    "        state[\"normalized_id\"] = result\n",
    "        state[\"source\"] = \"ChEMBL\"\n",
    "        print(f\"    âœ“ Found: {result}\")\n",
    "    else:\n",
    "        print(f\"    âœ— Not found\")\n",
    "    return state\n",
    "\n",
    "def try_tavily(state: DrugState) -> DrugState:\n",
    "    \"\"\"Try Tavily search + LLM\"\"\"\n",
    "    print(f\"  â†’ Trying Tavily + LLM...\")\n",
    "    result = search_tavily(state[\"drug_name\"])\n",
    "    if result:\n",
    "        state[\"normalized_id\"] = result\n",
    "        state[\"source\"] = \"Tavily+LLM\"\n",
    "        print(f\"    âœ“ Found: {result}\")\n",
    "    else:\n",
    "        print(f\"    âœ— Not found\")\n",
    "    return state\n",
    "\n",
    "def finalize(state: DrugState) -> DrugState:\n",
    "    \"\"\"Finalize normalization\"\"\"\n",
    "    if state.get(\"normalized_id\"):\n",
    "        print(f\"âœ… Normalized: {state['drug_name']} â†’ {state['normalized_id']} (via {state['source']})\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed to normalize: {state['drug_name']}\")\n",
    "    return state\n",
    "\n",
    "# Routing Logic\n",
    "def route_after_rxnorm(state: DrugState) -> str:\n",
    "    return \"finalize\" if state.get(\"normalized_id\") else \"try_chembl\"\n",
    "\n",
    "def route_after_chembl(state: DrugState) -> str:\n",
    "    return \"finalize\" if state.get(\"normalized_id\") else \"try_tavily\"\n",
    "\n",
    "def route_after_tavily(state: DrugState) -> str:\n",
    "    return \"finalize\"\n",
    "\n",
    "# Build LangGraph\n",
    "def build_normalization_graph():\n",
    "    \"\"\"Build the drug normalization LangGraph workflow\"\"\"\n",
    "    workflow = StateGraph(DrugState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"try_rxnorm\", try_rxnorm)\n",
    "    workflow.add_node(\"try_chembl\", try_chembl)\n",
    "    workflow.add_node(\"try_tavily\", try_tavily)\n",
    "    workflow.add_node(\"finalize\", finalize)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"try_rxnorm\")\n",
    "    \n",
    "    # Add conditional edges\n",
    "    workflow.add_conditional_edges(\"try_rxnorm\", route_after_rxnorm)\n",
    "    workflow.add_conditional_edges(\"try_chembl\", route_after_chembl)\n",
    "    workflow.add_conditional_edges(\"try_tavily\", route_after_tavily)\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Main API\n",
    "def normalize_drug(drug_name: str) -> Dict:\n",
    "    \"\"\"Normalize a single drug name\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Normalizing: {drug_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    graph = build_normalization_graph()\n",
    "    result = graph.invoke({\n",
    "        \"drug_name\": drug_name.strip(),\n",
    "        \"normalized_id\": None,\n",
    "        \"source\": None\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"drug_name\": drug_name,\n",
    "        \"normalized_id\": result.get(\"normalized_id\"),\n",
    "        \"source\": result.get(\"source\"),\n",
    "        \"success\": result.get(\"normalized_id\") is not None\n",
    "    }\n",
    "\n",
    "def normalize_multiple(drug_names: List[str]) -> Dict[str, Dict]:\n",
    "    \"\"\"Normalize multiple drug names\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Normalizing {len(drug_names)} drugs\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = {}\n",
    "    for drug in drug_names:\n",
    "        results[drug] = normalize_drug(drug)\n",
    "    \n",
    "    successful = sum(1 for r in results.values() if r[\"success\"])\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ… Success: {successful}/{len(drug_names)}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40905a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Neo4j Config\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "\n",
    "# DRKG Relationships\n",
    "DDI_RELS = [\"DRUGBANK::ddi-interactor-in::Compound:Compound\"]\n",
    "SIDE_EFFECT_RELS = [\"Hetionet::CcSE::Compound:Side Effect\", \"GNBR::Sa::Compound:Disease\"]\n",
    "\n",
    "def query_graph(drug_ids: List[str]) -> Dict:\n",
    "    \"\"\"Query Neo4j for drug interactions and side effects\"\"\"\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    results = {}\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        for drug in drug_ids:\n",
    "            print(f\"Querying graph for: {drug}\")\n",
    "            results[drug] = {'interactions': [], 'side_effects': []}\n",
    "            \n",
    "            # Drug-Drug Interactions\n",
    "            ddi_query = \"\"\"\n",
    "            MATCH (drug {Entity: $drug})-[r]-(partner)\n",
    "            WHERE r.Relationship IN $ddi_rels\n",
    "            RETURN DISTINCT partner.Entity AS interacting_drug\n",
    "            LIMIT 200\n",
    "            \"\"\"\n",
    "            ddi_records = session.run(ddi_query, drug=drug, ddi_rels=DDI_RELS)\n",
    "            for rec in ddi_records:\n",
    "                results[drug]['interactions'].append(rec['interacting_drug'])\n",
    "            \n",
    "            print(f\"  âœ“ Found {len(results[drug]['interactions'])} interactions\")\n",
    "            \n",
    "            # Side Effects\n",
    "            se_query = \"\"\"\n",
    "            MATCH (drug {Entity: $drug})-[r]-(effect)\n",
    "            WHERE r.Relationship IN $se_rels\n",
    "            RETURN DISTINCT effect.Entity AS side_effect\n",
    "            LIMIT 200\n",
    "            \"\"\"\n",
    "            se_records = session.run(se_query, drug=drug, se_rels=SIDE_EFFECT_RELS)\n",
    "            for rec in se_records:\n",
    "                results[drug]['side_effects'].append(rec['side_effect'])\n",
    "            \n",
    "            print(f\"  âœ“ Found {len(results[drug]['side_effects'])} side effects\")\n",
    "    \n",
    "    driver.close()\n",
    "    return results\n",
    "\n",
    "def analyze_with_llm(graph_data: Dict, drug_name_mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Analyze drug combination using LLM with proper drug names\n",
    "    \n",
    "    Args:\n",
    "        graph_data: Graph query results\n",
    "        drug_name_mapping: Dict mapping normalized_id -> original drug name\n",
    "    \"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        temperature=0.1,\n",
    "        api_key=GEMINI_API_KEY\n",
    "    )\n",
    "    \n",
    "    # Create drug name reference for LLM\n",
    "    drug_names_section = \"\\n## DRUG NAME REFERENCE:\\n\"\n",
    "    for drug_id, drug_name in drug_name_mapping.items():\n",
    "        drug_names_section += f\"- {drug_id} = **{drug_name}**\\n\"\n",
    "    \n",
    "    # Format context\n",
    "    context = \"\"\n",
    "    for drug_id, data in graph_data.items():\n",
    "        drug_name = drug_name_mapping.get(drug_id, drug_id)\n",
    "        context += f\"\\n## {drug_name} ({drug_id})\\n\"\n",
    "        \n",
    "        if data['interactions']:\n",
    "            context += f\"### Drug-Drug Interactions:\\n\"\n",
    "            for i, interaction in enumerate(data['interactions'][:10], 1):\n",
    "                context += f\"{i}. {interaction}\\n\"\n",
    "        else:\n",
    "            context += \"### Drug-Drug Interactions: None found\\n\"\n",
    "        \n",
    "        if data['side_effects']:\n",
    "            context += f\"### Side Effects:\\n\"\n",
    "            for i, effect in enumerate(data['side_effects'][:15], 1):\n",
    "                context += f\"{i}. {effect}\\n\"\n",
    "        else:\n",
    "            context += \"### Side Effects: None found\\n\"\n",
    "    \n",
    "    # Check for mutual interactions\n",
    "    drug_codes = list(graph_data.keys())\n",
    "    mutual = []\n",
    "    for d1 in drug_codes:\n",
    "        for d2 in drug_codes:\n",
    "            if d1 != d2 and d2 in graph_data[d1]['interactions']:\n",
    "                name1 = drug_name_mapping.get(d1, d1)\n",
    "                name2 = drug_name_mapping.get(d2, d2)\n",
    "                mutual.append(f\"{name1} ({d1}) â†” {name2} ({d2})\")\n",
    "    \n",
    "    prompt = f\"\"\"You are a pharmaceutical expert. Analyze this drug combination for patient safety.\n",
    "\n",
    "{drug_names_section}\n",
    "\n",
    "DRUGS IN COMBINATION:\n",
    "{', '.join([f\"{drug_name_mapping.get(code, code)} ({code})\" for code in drug_codes])}\n",
    "\n",
    "KNOWLEDGE GRAPH DATA FROM DRKG:\n",
    "{context}\n",
    "\n",
    "DIRECT INTERACTIONS DETECTED BETWEEN INPUT DRUGS:\n",
    "{chr(10).join(mutual) if mutual else \"No direct interactions found between the input drugs\"}\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. Always use the actual drug names (from DRUG NAME REFERENCE above)\n",
    "2. Convert all DrugBank IDs to drug names when discussing them\n",
    "3. Explain interactions in plain language\n",
    "4. For MESH disease codes (e.g., Disease::MESH:D001986), provide the condition name if you know it\n",
    "\n",
    "Provide your analysis in this format:\n",
    "\n",
    "## 1. Drug Names & Overview\n",
    "List each drug with its common name and therapeutic class\n",
    "\n",
    "## 2. Overall Safety Assessment\n",
    "Risk level: [Low/Moderate/High/Critical]\n",
    "Brief explanation (2-3 sentences)\n",
    "\n",
    "## 3. Direct Drug-Drug Interactions\n",
    "Explain interactions between the input drugs (if any)\n",
    "- Which drugs interact\n",
    "- Mechanism of interaction\n",
    "- Clinical significance\n",
    "\n",
    "## 4. Interactions with Other Medications\n",
    "Explain notable interactions with commonly prescribed drugs found in the data\n",
    "- Mention the drug classes involved\n",
    "- Clinical relevance\n",
    "\n",
    "## 5. Side Effects Profile\n",
    "Common side effects for each drug\n",
    "- Convert MESH codes to condition names when possible\n",
    "- Note overlapping side effects\n",
    "- Indicate severity\n",
    "\n",
    "## 6. Clinical Recommendations\n",
    "- Can these drugs be taken together safely?\n",
    "- Required monitoring (e.g., INR for anticoagulants, renal function)\n",
    "- Timing considerations\n",
    "- Contraindications\n",
    "\n",
    "ANALYSIS:\"\"\"\n",
    "    \n",
    "    print(\"\\nGenerating clinical analysis with LLM...\")\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "def analyze_prescription(medicines: str) -> Dict:\n",
    "    \"\"\"Complete end-to-end analysis pipeline with proper drug name tracking\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"PRESCRIPTION ANALYSIS PIPELINE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Step 1: Extract medicines\n",
    "    drug_list = [m.strip() for m in medicines.split(',') if m.strip()]\n",
    "    print(f\"\\nðŸ“‹ Extracted {len(drug_list)} medicines: {drug_list}\")\n",
    "    \n",
    "    # Step 2: Normalize\n",
    "    print(f\"\\nðŸ”„ Step 1: Normalizing drug names...\")\n",
    "    norm_results = normalize_multiple(drug_list)\n",
    "    \n",
    "    # Step 3: Build mapping of normalized_id -> original drug name\n",
    "    drug_name_mapping = {}\n",
    "    normalized_ids = []\n",
    "    \n",
    "    for original_name, result in norm_results.items():\n",
    "        if result[\"success\"]:\n",
    "            normalized_ids.append(result[\"normalized_id\"])\n",
    "            drug_name_mapping[result[\"normalized_id\"]] = original_name\n",
    "    \n",
    "    if not normalized_ids:\n",
    "        return {\n",
    "            \"error\": \"No drugs could be normalized\",\n",
    "            \"normalization_results\": norm_results\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nâœ… Successfully normalized {len(normalized_ids)} drugs\")\n",
    "    print(f\"   Mapping: {drug_name_mapping}\")\n",
    "    \n",
    "    # Step 4: Query graph\n",
    "    print(f\"\\nðŸ“Š Step 2: Querying knowledge graph...\")\n",
    "    graph_data = query_graph(normalized_ids)\n",
    "    \n",
    "    # Step 5: Analyze with LLM (pass drug name mapping)\n",
    "    print(f\"\\nðŸ¤– Step 3: Generating clinical analysis...\")\n",
    "    analysis = analyze_with_llm(graph_data, drug_name_mapping)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"CLINICAL ANALYSIS\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    print(analysis)\n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"input\": medicines,\n",
    "        \"extracted_drugs\": drug_list,\n",
    "        \"normalization_results\": norm_results,\n",
    "        \"normalized_ids\": normalized_ids,\n",
    "        \"drug_name_mapping\": drug_name_mapping,\n",
    "        \"graph_data\": graph_data,\n",
    "        \"analysis\": analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc35a89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PRESCRIPTION ANALYSIS PIPELINE\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Extracted 3 medicines: ['Aspirin', 'Ibuprofen', 'Warfarin']\n",
      "\n",
      "ðŸ”„ Step 1: Normalizing drug names...\n",
      "\n",
      "============================================================\n",
      "Normalizing 3 drugs\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Normalizing: Aspirin\n",
      "============================================================\n",
      "  â†’ Trying RxNorm...\n",
      "    âœ“ Found: Compound::DB00945\n",
      "âœ… Normalized: Aspirin â†’ Compound::DB00945 (via RxNorm)\n",
      "\n",
      "============================================================\n",
      "Normalizing: Ibuprofen\n",
      "============================================================\n",
      "  â†’ Trying RxNorm...\n",
      "    âœ“ Found: Compound::DB01050\n",
      "âœ… Normalized: Ibuprofen â†’ Compound::DB01050 (via RxNorm)\n",
      "\n",
      "============================================================\n",
      "Normalizing: Warfarin\n",
      "============================================================\n",
      "  â†’ Trying RxNorm...\n",
      "    âœ“ Found: Compound::DB00682\n",
      "âœ… Normalized: Warfarin â†’ Compound::DB00682 (via RxNorm)\n",
      "\n",
      "============================================================\n",
      "âœ… Success: 3/3\n",
      "============================================================\n",
      "\n",
      "\n",
      "âœ… Successfully normalized 3 drugs\n",
      "   Mapping: {'Compound::DB00945': 'Aspirin', 'Compound::DB01050': 'Ibuprofen', 'Compound::DB00682': 'Warfarin'}\n",
      "\n",
      "ðŸ“Š Step 2: Querying knowledge graph...\n",
      "Querying graph for: Compound::DB00945\n",
      "  âœ“ Found 200 interactions\n",
      "  âœ“ Found 123 side effects\n",
      "Querying graph for: Compound::DB01050\n",
      "  âœ“ Found 200 interactions\n",
      "  âœ“ Found 200 side effects\n",
      "Querying graph for: Compound::DB00682\n",
      "  âœ“ Found 200 interactions\n",
      "  âœ“ Found 16 side effects\n",
      "\n",
      "ðŸ¤– Step 3: Generating clinical analysis...\n",
      "\n",
      "Generating clinical analysis with LLM...\n",
      "\n",
      "======================================================================\n",
      "CLINICAL ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "## 1. Drug Names & Overview\n",
      "\n",
      "*   **Aspirin (Compound::DB00945):** Antiplatelet agent, nonsteroidal anti-inflammatory drug (NSAID).\n",
      "*   **Ibuprofen (Compound::DB01050):** Nonsteroidal anti-inflammatory drug (NSAID).\n",
      "*   **Warfarin (Compound::DB00682):** Anticoagulant.\n",
      "\n",
      "## 2. Overall Safety Assessment\n",
      "\n",
      "Risk level: **Critical**\n",
      "\n",
      "This combination of Aspirin, Ibuprofen, and Warfarin presents a critical safety risk due to the significantly increased risk of bleeding. All three drugs have anticoagulant or antiplatelet effects, and their combined use can lead to severe and potentially fatal bleeding complications. This combination should generally be avoided unless there are very specific clinical circumstances and close monitoring is possible.\n",
      "\n",
      "## 3. Direct Drug-Drug Interactions\n",
      "\n",
      "No direct interactions were found between the input drugs in the provided knowledge graph. However, the absence of a direct interaction in the knowledge graph does not negate the well-established pharmacodynamic interaction between these drugs.\n",
      "\n",
      "*   **Aspirin and Ibuprofen:** Both are NSAIDs and can compete for binding sites, potentially reducing the antiplatelet effect of aspirin if ibuprofen is taken before aspirin.\n",
      "*   **Aspirin and Warfarin:** Aspirin inhibits platelet aggregation and has anticoagulant properties. Warfarin inhibits vitamin K-dependent clotting factors. Combining these drugs significantly increases the risk of bleeding.\n",
      "*   **Ibuprofen and Warfarin:** Ibuprofen, like other NSAIDs, can increase the risk of bleeding, especially in patients taking anticoagulants like warfarin. NSAIDs can also affect platelet function and potentially increase the risk of gastrointestinal bleeding, which can be exacerbated by warfarin.\n",
      "\n",
      "## 4. Interactions with Other Medications\n",
      "\n",
      "The provided data shows several drug-drug interactions for each medication. Some notable interactions include:\n",
      "\n",
      "*   **Aspirin, Ibuprofen, and Warfarin interact with similar drugs:** All three drugs interact with Compound::DB01087, Compound::DB01072, Compound::DB06290, and Compound::DB01392. Without knowing the actual drug names, it's difficult to assess the clinical relevance. However, the fact that all three drugs interact with the same compounds suggests a potential for additive or synergistic effects, increasing the risk of adverse events.\n",
      "*   **Aspirin and Warfarin interact with Compound::DB00997 and Compound::DB01048:** This further highlights the potential for increased bleeding risk when combining these medications with other drugs that affect coagulation or platelet function.\n",
      "\n",
      "## 5. Side Effects Profile\n",
      "\n",
      "*   **Aspirin:**\n",
      "    *   Side Effects: Hemorrhage (Disease::MESH:D006996), Asthma (Disease::MESH:D001249), Reye Syndrome (Disease::MESH:D012033), Drug Hypersensitivity (Disease::MESH:D004487), Angioedema (Disease::MESH:D000799), Gastrointestinal Hemorrhage (Disease::MESH:D005756), Urticaria (Disease::MESH:D014534), Nausea (Disease::MESH:D009422), Vomiting (Disease::MESH:D014774), Dyspepsia (Disease::MESH:D004342), Abdominal Pain (Disease::MESH:D000014).\n",
      "*   **Ibuprofen:**\n",
      "    *   Side Effects: Kidney Diseases (Disease::MESH:D007674), Renal Insufficiency (Disease::MESH:D012022), Fluid Retention (Disease::MESH:D005475), Edema (Disease::MESH:D004571), Gastrointestinal Hemorrhage (Disease::MESH:D005756), Urticaria (Disease::MESH:D014534), Nausea (Disease::MESH:D009422), Vomiting (Disease::MESH:D014774), Dyspepsia (Disease::MESH:D004342), Abdominal Pain (Disease::MESH:D000014).\n",
      "*   **Warfarin:**\n",
      "    *   Side Effects: Hemorrhage (Disease::MESH:D006996), Skin Necrosis (Disease::MESH:D012871), Purple Toe Syndrome (Disease::MESH:D061205), Diarrhea (Disease::MESH:D003923), Nausea (Disease::MESH:D009422), Vomiting (Disease::MESH:D014774), Abdominal Pain (Disease::MESH:D000014).\n",
      "\n",
      "**Overlapping Side Effects:** All three drugs share common side effects such as gastrointestinal hemorrhage, nausea, vomiting, and abdominal pain, which can be exacerbated when used together. The most concerning overlapping side effect is hemorrhage, which is significantly increased with this combination.\n",
      "\n",
      "## 6. Clinical Recommendations\n",
      "\n",
      "**Contraindications:** This combination is generally contraindicated due to the high risk of bleeding.\n",
      "\n",
      "**Can these drugs be taken together safely?** No, this combination is generally not safe and should be avoided unless there are very specific clinical circumstances and close monitoring is possible.\n",
      "\n",
      "**Required monitoring:** If this combination is unavoidable, very close monitoring is essential:\n",
      "\n",
      "*   **INR (International Normalized Ratio):** Frequent monitoring of INR is crucial to ensure warfarin is within the therapeutic range and to detect any signs of over-anticoagulation.\n",
      "*   **Complete Blood Count (CBC):** Monitor for signs of anemia or thrombocytopenia.\n",
      "*   **Renal Function:** Monitor renal function, especially in elderly patients or those with pre-existing kidney disease.\n",
      "*   **Gastrointestinal Monitoring:** Monitor for signs and symptoms of gastrointestinal bleeding (e.g., melena, hematemesis).\n",
      "\n",
      "**Timing considerations:** If aspirin and ibuprofen are used together, administer aspirin at least 30 minutes before or 8 hours after ibuprofen to minimize the interaction. However, this timing consideration does not negate the overall increased risk of bleeding when combined with warfarin.\n",
      "\n",
      "**In summary,** the combination of Aspirin, Ibuprofen, and Warfarin carries a critical risk of bleeding and should be avoided unless absolutely necessary and with very close monitoring. Alternative therapies should be considered whenever possible.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = analyze_prescription(\"Aspirin, Ibuprofen, Warfarin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436ee54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
